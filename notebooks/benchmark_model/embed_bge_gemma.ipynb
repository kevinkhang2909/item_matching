{
 "cells": [
  {
   "cell_type": "code",
   "id": "28f6df8c7caed3f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:10.007288Z",
     "start_time": "2024-11-21T03:59:08.058293Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import duckdb\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from autofaiss import build_index\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from core_pro.ultilities import make_dir, make_sync_folder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5c3e4a05690aebce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:10.084246Z",
     "start_time": "2024-11-21T03:59:10.012358Z"
    }
   },
   "source": [
    "path = make_sync_folder('Item_Matching_Test')\n",
    "file = path / 'clean.parquet'\n",
    "\n",
    "query = f\"\"\"select * from read_parquet('{file}')\"\"\"\n",
    "df = duckdb.sql(query).pl()\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 11)\n",
       "┌────────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
       "│ item_id    ┆ item_name  ┆ shop_id   ┆ shop_name ┆ … ┆ image_url ┆ item_name ┆ file_path ┆ exists │\n",
       "│ ---        ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ _clean    ┆ ---       ┆ ---    │\n",
       "│ i64        ┆ str        ┆ i64       ┆ str       ┆   ┆ str       ┆ ---       ┆ str       ┆ bool   │\n",
       "│            ┆            ┆           ┆           ┆   ┆           ┆ str       ┆           ┆        │\n",
       "╞════════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
       "│ 2582362917 ┆ Kẹp Tóc    ┆ 851157471 ┆ Shopee    ┆ … ┆ http://f. ┆ kẹp tóc   ┆ /home/kev ┆ true   │\n",
       "│ 1          ┆ càng cua   ┆           ┆ Choice    ┆   ┆ shopee.vn ┆ càng cua  ┆ in/Downlo ┆        │\n",
       "│            ┆ Choice     ┆           ┆ Việt Nam  ┆   ┆ /file/sg- ┆ choice    ┆ ads/Item_ ┆        │\n",
       "│            ┆ Việt N…    ┆           ┆           ┆   ┆ 111…      ┆ việt n…   ┆ Mat…      ┆        │\n",
       "│ 2910814553 ┆ Áo dây CÚP ┆ 107431696 ┆ Honestss  ┆ … ┆ http://f. ┆ áo dây    ┆ /home/kev ┆ true   │\n",
       "│ 1          ┆ ngực phối  ┆ 7         ┆           ┆   ┆ shopee.vn ┆ cúp ngực  ┆ in/Downlo ┆        │\n",
       "│            ┆ ren sexy … ┆           ┆           ┆   ┆ /file/vn- ┆ phối ren  ┆ ads/Item_ ┆        │\n",
       "│            ┆            ┆           ┆           ┆   ┆ 111…      ┆ sexy …    ┆ Mat…      ┆        │\n",
       "│ 6092976691 ┆ Miếng Dán  ┆ 275954116 ┆ Dan       ┆ … ┆ http://f. ┆ miếng dán ┆ /home/kev ┆ true   │\n",
       "│            ┆ Ngực ❤️FREE ┆           ┆ Bikini    ┆   ┆ shopee.vn ┆ ngực      ┆ in/Downlo ┆        │\n",
       "│            ┆ SHIP❤️ Hộ… ┆           ┆           ┆   ┆ /file/vn- ┆ freeship  ┆ ads/Item_ ┆        │\n",
       "│            ┆            ┆           ┆           ┆   ┆ 111…      ┆ hộp 5 …   ┆ Mat…      ┆        │\n",
       "│ 2332837174 ┆ Găng tay   ┆ 960970699 ┆ Winter Ma ┆ … ┆ http://f. ┆ găng tay  ┆ /home/kev ┆ true   │\n",
       "│ 7          ┆ phao nam   ┆           ┆ rket      ┆   ┆ shopee.vn ┆ phao nam  ┆ in/Downlo ┆        │\n",
       "│            ┆ chống lạnh ┆           ┆           ┆   ┆ /file/vn- ┆ chống     ┆ ads/Item_ ┆        │\n",
       "│            ┆ s…         ┆           ┆           ┆   ┆ 111…      ┆ lạnh s…   ┆ Mat…      ┆        │\n",
       "│ 1359945053 ┆ Quần Dài   ┆ 704317817 ┆ KHOUSE-한 ┆ … ┆ http://f. ┆ quần dài  ┆ /home/kev ┆ true   │\n",
       "│ 6          ┆ Thể Thao   ┆           ┆ 국 여성   ┆   ┆ shopee.vn ┆ thể thao  ┆ in/Downlo ┆        │\n",
       "│            ┆ Chống Nắng ┆           ┆ 패션      ┆   ┆ /file/sg- ┆ chống     ┆ ads/Item_ ┆        │\n",
       "│            ┆ D…         ┆           ┆           ┆   ┆ 111…      ┆ nắng d…   ┆ Mat…      ┆        │\n",
       "└────────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item_id</th><th>item_name</th><th>shop_id</th><th>shop_name</th><th>level1_global_be_category</th><th>description</th><th>images</th><th>image_url</th><th>item_name_clean</th><th>file_path</th><th>exists</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td></tr></thead><tbody><tr><td>25823629171</td><td>&quot;Kẹp&nbsp;Tóc&nbsp;càng&nbsp;cua&nbsp;Choice&nbsp;Việt&nbsp;N…</td><td>851157471</td><td>&quot;Shopee&nbsp;Choice&nbsp;Việt&nbsp;Nam&quot;</td><td>&quot;Fashion&nbsp;Accessories&quot;</td><td>&quot;[{&quot;t&quot;:&quot;✪&nbsp;THÔNG&nbsp;TIN&nbsp;SẢN&nbsp;PHẨM&nbsp;\\n…</td><td>&quot;sg-11134301-7rd4i-lvolqk5ptysj…</td><td>&quot;http://f.shopee.vn/file/sg-111…</td><td>&quot;kẹp&nbsp;tóc&nbsp;càng&nbsp;cua&nbsp;choice&nbsp;việt&nbsp;n…</td><td>&quot;/home/kevin/Downloads/Item_Mat…</td><td>true</td></tr><tr><td>29108145531</td><td>&quot;Áo&nbsp;dây&nbsp;CÚP&nbsp;ngực&nbsp;phối&nbsp;ren&nbsp;sexy&nbsp;…</td><td>1074316967</td><td>&quot;Honestss&quot;</td><td>&quot;Women&nbsp;Clothes&quot;</td><td>&quot;Áo&nbsp;dây&nbsp;CÚP&nbsp;ngực&nbsp;phối&nbsp;ren&nbsp;sexy&nbsp;…</td><td>&quot;vn-11134207-7r98o-lz1svcz309xp…</td><td>&quot;http://f.shopee.vn/file/vn-111…</td><td>&quot;áo&nbsp;dây&nbsp;cúp&nbsp;ngực&nbsp;phối&nbsp;ren&nbsp;sexy&nbsp;…</td><td>&quot;/home/kevin/Downloads/Item_Mat…</td><td>true</td></tr><tr><td>6092976691</td><td>&quot;Miếng&nbsp;Dán&nbsp;Ngực&nbsp;❤️FREESHIP❤️&nbsp;Hộ…</td><td>275954116</td><td>&quot;Dan&nbsp;Bikini&quot;</td><td>&quot;Women&nbsp;Clothes&quot;</td><td>&quot;MIẾNG&nbsp;DÁN&nbsp;NGỰC&nbsp;SILICON&nbsp;HÀN&nbsp;QUỐ…</td><td>&quot;vn-11134201-7r98o-lyynyaibhgv5…</td><td>&quot;http://f.shopee.vn/file/vn-111…</td><td>&quot;miếng&nbsp;dán&nbsp;ngực&nbsp;freeship&nbsp;hộp&nbsp;5&nbsp;…</td><td>&quot;/home/kevin/Downloads/Item_Mat…</td><td>true</td></tr><tr><td>23328371747</td><td>&quot;Găng&nbsp;tay&nbsp;phao&nbsp;nam&nbsp;chống&nbsp;lạnh&nbsp;s…</td><td>960970699</td><td>&quot;Winter Market&quot;</td><td>&quot;Fashion&nbsp;Accessories&quot;</td><td>&quot;Găng&nbsp;tay&nbsp;phao,&nbsp;bao&nbsp;tay&nbsp;phao&nbsp;đi…</td><td>&quot;vn-11134211-7r98o-ln8wlsop9p7c…</td><td>&quot;http://f.shopee.vn/file/vn-111…</td><td>&quot;găng&nbsp;tay&nbsp;phao&nbsp;nam&nbsp;chống&nbsp;lạnh&nbsp;s…</td><td>&quot;/home/kevin/Downloads/Item_Mat…</td><td>true</td></tr><tr><td>13599450536</td><td>&quot;Quần&nbsp;Dài&nbsp;Thể&nbsp;Thao&nbsp;Chống&nbsp;Nắng&nbsp;D…</td><td>704317817</td><td>&quot;KHOUSE-한국&nbsp;여성&nbsp;패션&quot;</td><td>&quot;Women&nbsp;Clothes&quot;</td><td>&quot;[{&quot;t&quot;:&quot;Xuất&nbsp;xứ:&nbsp;Thâm&nbsp;Quyến\\nTấ…</td><td>&quot;sg-11134201-7qveg-lgomar6dayh8…</td><td>&quot;http://f.shopee.vn/file/sg-111…</td><td>&quot;quần&nbsp;dài&nbsp;thể&nbsp;thao&nbsp;chống&nbsp;nắng&nbsp;d…</td><td>&quot;/home/kevin/Downloads/Item_Mat…</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "221b61297efcc3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.126771Z",
     "start_time": "2024-11-21T03:59:10.145541Z"
    }
   },
   "source": [
    "name = 'bge_gemma'\n",
    "path_tmp_array = Path(path / f'tmp/array/{name}')\n",
    "path_tmp_ds = Path(path / f'tmp/ds/{name}')\n",
    "make_dir(path_tmp_ds)\n",
    "make_dir(path_tmp_array)\n",
    "\n",
    "file_embed = path_tmp_array / 'embed.npy'\n",
    "if not file_embed.exists():\n",
    "    model = BGEM3FlagModel('BAAI/bge-multilingual-gemma2', use_fp16=False)\n",
    "    embeddings = model.encode(\n",
    "        df['item_name_clean'].to_list(),\n",
    "        batch_size=1,\n",
    "        max_length=80,\n",
    "        return_dense=True,\n",
    "        return_sparse=False,\n",
    "        return_colbert_vecs=False\n",
    "    )['dense_vecs']\n",
    "    np.save(file_embed, embeddings)\n",
    "else:\n",
    "    embeddings = np.load(file_embed)\n",
    "print(embeddings.shape)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 25 files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca78beec845a40a6a0eeb000677ca7e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f1ff741b93d44f1a710ca52653e5bb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 7.78 GiB of which 114.19 MiB is free. Process 2235 has 132.68 MiB memory in use. Process 33171 has 19.46 MiB memory in use. Including non-PyTorch memory, this process has 7.05 GiB memory in use. Of the allocated memory 6.92 GiB is allocated by PyTorch, and 3.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m file_embed \u001B[38;5;241m=\u001B[39m path_tmp_array \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124membed.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_embed\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m----> 9\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mBGEM3FlagModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBAAI/bge-multilingual-gemma2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(\n\u001B[1;32m     11\u001B[0m         df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mitem_name_clean\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto_list(),\n\u001B[1;32m     12\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m         return_colbert_vecs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     )[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdense_vecs\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     18\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(file_embed, embeddings)\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/FlagEmbedding/bge_m3.py:56\u001B[0m, in \u001B[0;36mBGEM3FlagModel.__init__\u001B[0;34m(self, model_name_or_path, pooling_method, normalize_embeddings, use_fp16, device)\u001B[0m\n\u001B[1;32m     54\u001B[0m         use_fp16 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_fp16: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mhalf()\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_gpus \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1337\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1338\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1340\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 900\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 900\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 900\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    924\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    925\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    926\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 927\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    930\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/item_match/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1320\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1321\u001B[0m             device,\n\u001B[1;32m   1322\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1323\u001B[0m             non_blocking,\n\u001B[1;32m   1324\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1325\u001B[0m         )\n\u001B[0;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1328\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 7.78 GiB of which 114.19 MiB is free. Process 2235 has 132.68 MiB memory in use. Process 33171 has 19.46 MiB memory in use. Including non-PyTorch memory, this process has 7.05 GiB memory in use. Of the allocated memory 6.92 GiB is allocated by PyTorch, and 3.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b95e12aa6944cd3e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199085379Z",
     "start_time": "2024-11-21T03:47:31.556995Z"
    }
   },
   "source": [
    "df = df.with_columns(pl.Series(values=embeddings, name='embed'))\n",
    "dataset = Dataset.from_polars(df)\n",
    "dataset.set_format(type='numpy', columns=['embed'], output_all_columns=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "96cc5afcf31a1e6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199342219Z",
     "start_time": "2024-11-21T03:47:31.679352Z"
    }
   },
   "source": [
    "path_index = Path(path / 'tmp/index')\n",
    "build_index(\n",
    "    embeddings=embeddings,\n",
    "    index_path=str(path_index / f'ip.index'),\n",
    "    index_infos_path=str(path_index / f'index.json'),\n",
    "    save_on_disk=True,\n",
    "    metric_type='ip',\n",
    "    verbose=30,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2743.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<faiss.swigfaiss_avx2.IndexHNSWFlat; proxy of <Swig Object of type 'faiss::IndexHNSWFlat *' at 0x7b8858053ea0> >,\n",
       " {'index_key': 'HNSW15',\n",
       "  'index_param': 'efSearch=5226',\n",
       "  'index_path': '/home/kevin/Downloads/Item_Matching_Test/tmp/index/ip.index',\n",
       "  'size in bytes': 42050218,\n",
       "  'avg_search_speed_ms': 9.97823628438878,\n",
       "  '99p_search_speed_ms': 10.557658101897687,\n",
       "  'reconstruction error %': 0.0,\n",
       "  'nb vectors': 9936,\n",
       "  'vectors dimension': 1024,\n",
       "  'compression ratio': 0.9678393581693203})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6efdce62f49c27b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199597932Z",
     "start_time": "2024-11-21T03:47:49.423495Z"
    }
   },
   "source": [
    "# add index\n",
    "dataset.load_faiss_index('embed', path_index / f'ip.index')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3bcba75a987dd8c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199727160Z",
     "start_time": "2024-11-21T03:47:49.465298Z"
    }
   },
   "source": [
    "score, result = dataset.get_nearest_examples_batch(\n",
    "    'embed',\n",
    "    np.asarray(dataset['embed']),\n",
    "    k=5\n",
    ")\n",
    "\n",
    "dict_ = {'score': [list(i) for i in score]}\n",
    "df_score = pl.DataFrame(dict_)\n",
    "df_result = (\n",
    "    pl.DataFrame(result).drop(['embed'])\n",
    "    .select(pl.all().name.prefix(f'db_'))\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ae3b4d1db34781b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199856014Z",
     "start_time": "2024-11-21T03:48:21.522065Z"
    }
   },
   "source": [
    "df_match = pl.concat([df, df_result, df_score], how='horizontal')\n",
    "col_explode = [i for i in df_match.columns if 'notebooks' in i] + ['score']"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c77a28d769f090a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.199953605Z",
     "start_time": "2024-11-21T03:49:47.462896Z"
    }
   },
   "source": [
    "path_export = path / 'text_match'\n",
    "make_dir(path_export)\n",
    "df_match.write_parquet(path_export / f'{name}.parquet')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "2dacba735258ef3d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T03:59:13.200047873Z",
     "start_time": "2024-11-21T03:45:55.640192Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
